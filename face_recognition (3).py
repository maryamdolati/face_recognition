# -*- coding: utf-8 -*-
"""Face Recognition.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JzaCB0Z4UZSJV-avazUiRHmKB6AM1RNW
"""

!pip -q install mtcnn tqdm
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

import os
import cv2
import numpy as np
import pandas as pd
from tqdm import tqdm
from PIL import Image
from matplotlib import pyplot as plt
from mtcnn.mtcnn import MTCNN
from tensorflow import keras
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import models
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras import regularizers
from tensorflow.keras import optimizers, losses
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.metrics import classification_report, confusion_matrix
import shutil

BASE_DIR = "/content/drive/MyDrive/FacialRecognitionProject/yalefaces"
DIRECTORY_train = f"{BASE_DIR}/train/"
DIRECTORY_test  = f"{BASE_DIR}/test/"
SAMPLE_FILE = f"{DIRECTORY_test}subject03.glasses.gif"

IMAGE_HEIGHT = 160
IMAGE_WIDTH  = 160
EPOCHS       = 25
BATCH_SIZE   = 20
SEED         = 42

def list_files(directory, contains="subject"):
  return [f for f in os.listdir(directory) if contains in f]

def draw_image_with_boxes(data, result_list):
  plt.imshow(data)
  ax = plt.gca()
  from matplotlib.patches import Rectangle
  for result in result_list:
    x, y, width, height = result['box']
    rect = Rectangle((x, y), width, height, fill=False, color='red')
    ax.add_patch(rect)
  plt.axis('off')
  plt.show()

detector = MTCNN()

def extract_face_from_file(filename, required_size=(160, 160)):
  image = Image.open(filename)
  return extract_face(image, required_size)

def extract_face(image, required_size=(160, 160)):
  image = image.convert('RGB')
  pixels = np.asarray(image)
  results = detector.detect_faces(pixels)
  if len(results) == 0:
    return None
  x1, y1, width, height = results[0]['box']
  x1, y1 = abs(x1), abs(y1)
  x2, y2 = x1 + width, y1 + height
  x1, y1 = max(0, x1), max(0, y1)
  x2, y2 = min(pixels.shape[1], x2), min(pixels.shape[0], y2)
  face = pixels[y1:y2, x1:x2]
  face_img = Image.fromarray(face)
  face_img = face_img.resize(required_size)
  face_array_rgb = np.asarray(face_img)
  gray_face = cv2.cvtColor(face_array_rgb, cv2.COLOR_RGB2GRAY)
  return gray_face

train_files = pd.DataFrame(list_files(DIRECTORY_train, "subject"), columns=["filename"])
test_files  = pd.DataFrame(list_files(DIRECTORY_test,  "subject"), columns=["filename"])

def make_df(df):
  parts = df["filename"].str.split(".", expand=True)
  df2 = pd.DataFrame()
  df2["subject"]  = pd.to_numeric(parts[0].str.replace("subject", "", regex=False), errors="coerce")
  df2["category"] = parts[1]
  df2["filename"] = df["filename"]
  df2 = df2.dropna(subset=["subject"]).reset_index(drop=True)
  df2["subject"] = df2["subject"].astype(int)
  return df2

df_train = make_df(train_files)
df_test  = make_df(test_files)

def load_faces_from_dir(df, base_dir):
  faces = []
  kept  = []
  for fname in tqdm(df["filename"], desc=f"Extracting faces from {os.path.basename(base_dir)}"):
    path = os.path.join(base_dir, fname)
    face = extract_face_from_file(path, required_size=(IMAGE_WIDTH, IMAGE_HEIGHT))
    if face is not None and face.size > 0:
      faces.append(face)
      kept.append(fname)
  return np.asarray(faces), kept

faces_train, kept_train = load_faces_from_dir(df_train, DIRECTORY_train)
faces_test,  kept_test  = load_faces_from_dir(df_test,  DIRECTORY_test)

df_train = df_train[df_train["filename"].isin(kept_train)].reset_index(drop=True)
df_test  = df_test[df_test["filename"].isin(kept_test)].reset_index(drop=True)

shutil.rmtree('data', ignore_errors=True)
os.makedirs('data/train', exist_ok=True)
os.makedirs('data/test', exist_ok=True)

def save_keras_dataset(setname, df, base_dir):
  data = df.sort_values("subject").reset_index(drop=True)
  counts = {}
  for _, row in tqdm(data.iterrows(), total=len(data), desc=f"Saving {setname}"):
    label = int(row["subject"])
    fname = row["filename"]
    path  = os.path.join(base_dir, fname)
    face  = extract_face_from_file(path, required_size=(IMAGE_WIDTH, IMAGE_HEIGHT))
    if face is None:
      continue
    counts[label] = counts.get(label, 0) + 1
    out_dir = f"data/{setname}/class_{label}"
    os.makedirs(out_dir, exist_ok=True)
    out_path = f"{out_dir}/class_{label}_{counts[label]}.png"
    cv2.imwrite(out_path, face)

save_keras_dataset("train", df_train, DIRECTORY_train)
save_keras_dataset("test",  df_test,  DIRECTORY_test)

train_gen = ImageDataGenerator(rescale=1./255)
test_gen  = ImageDataGenerator(rescale=1./255)

training_generator = train_gen.flow_from_directory(
    "data/train",
    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    color_mode='grayscale',
    shuffle=True,
    seed=SEED
)

validation_generator = test_gen.flow_from_directory(
    "data/test",
    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    color_mode='grayscale',
    shuffle=False
)

num_classes = len(training_generator.class_indices)

class MCDropout(keras.layers.Dropout):
  def call(self, inputs, training=None):
    return super().call(inputs, training=True)

model = models.Sequential()
model.add(Conv2D(32, kernel_size=(3, 3), activation='linear',
                 input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, 1), padding='same'))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu',
                 kernel_regularizer=regularizers.l2(l2=0.01)))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(128, (3, 3), activation='relu',
                 kernel_regularizer=regularizers.l2(l2=0.01)))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Flatten())
model.add(Dense(512, activation='relu',
                kernel_initializer="glorot_uniform",
                kernel_regularizer=regularizers.l2(l2=0.01)))
model.add(MCDropout(rate=0.5))
model.add(Dense(num_classes, activation='softmax',
                kernel_initializer="glorot_uniform"))
model.summary()

early_stopping = EarlyStopping(monitor="val_accuracy", patience=5, restore_best_weights=True)

model.compile(
    loss=losses.CategoricalCrossentropy(from_logits=False),
    optimizer=optimizers.Adam(learning_rate=0.0003),
    metrics=["accuracy"]
)

history = model.fit(
    training_generator,
    epochs=EPOCHS,
    validation_data=validation_generator,
    callbacks=[early_stopping],
    verbose=1
)

plt.plot(history.history['accuracy'], label='train_acc')
plt.plot(history.history['val_accuracy'], label='val_acc')
plt.legend()
plt.show()
plt.plot(history.history['loss'], label='train_loss')
plt.plot(history.history['val_loss'], label='val_loss')
plt.legend()
plt.show()

Y_pred = model.predict(validation_generator, verbose=0)
y_pred = np.argmax(Y_pred, axis=1)
print(classification_report(validation_generator.classes, y_pred))
print(confusion_matrix(validation_generator.classes, y_pred))