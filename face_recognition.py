# -*- coding: utf-8 -*-
"""Face Recognition.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jO533hm35WZFEVriFNISmGjPgaFWZwOJ
"""

!pip install facenet-pytorch torch torchvision scikit-learn opencv-python joblib tqdm numpy pillow

import os, cv2, joblib, numpy as np, torch
from sklearn.datasets import fetch_lfw_people
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import classification_report, accuracy_score
from sklearn.svm import SVC
from facenet_pytorch import MTCNN, InceptionResnetV1
from PIL import Image

def load_data():
    lfw = fetch_lfw_people(min_faces_per_person=5, color=True, resize=2.0, download_if_missing=True)
    images = [Image.fromarray(img.astype(np.uint8)) for img in lfw.images]
    labels = [lfw.target_names[t] for t in lfw.target]
    return images, labels

def center_crop_resize(pil_img, size=160):
    w, h = pil_img.size
    s = min(w, h)
    left = (w - s) // 2
    top = (h - s) // 2
    pil_img = pil_img.crop((left, top, left + s, top + s)).resize((size, size))
    arr = np.float32(pil_img) / 255.0
    arr = np.transpose(arr, (2, 0, 1))
    return torch.tensor(arr)

def embed_faces(images, mtcnn, embedder, device):
    aligned = []
    for img in images:
        face = mtcnn(img)
        if face is None:
            face = center_crop_resize(img, 160)
        aligned.append(face)
    embs = []
    for i in range(0, len(aligned), 32):
        batch = torch.stack(aligned[i:i+32]).to(device)
        with torch.no_grad():
            e = embedder(batch).cpu().numpy()
        embs.extend(e)
    return np.array(embs)

def train():
    device = "cuda" if torch.cuda.is_available() else "cpu"
    mtcnn = MTCNN(image_size=160, margin=20, device=device, post_process=True, keep_all=False, selection_method="largest")
    embedder = InceptionResnetV1(pretrained="vggface2").eval().to(device)
    images, labels = load_data()
    X = embed_faces(images, mtcnn, embedder, device)
    y = np.array(labels)
    Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)
    le = LabelEncoder().fit(ytr)
    ytr, yte = le.transform(ytr), le.transform(yte)
    sc = StandardScaler().fit(Xtr)
    Xtr, Xte = sc.transform(Xtr), sc.transform(Xte)
    clf = SVC(C=10, gamma="scale", kernel="rbf", probability=True, class_weight="balanced", random_state=42)
    clf.fit(Xtr, ytr)
    yp = clf.predict(Xte)
    print("Accuracy:", accuracy_score(yte, yp))
    print(classification_report(yte, yp, target_names=le.classes_))
    os.makedirs("artifacts", exist_ok=True)
    joblib.dump(clf, "artifacts/svm.joblib")
    joblib.dump(sc, "artifacts/scaler.joblib")
    joblib.dump(le, "artifacts/encoder.joblib")

def webcam():
    device = "cuda" if torch.cuda.is_available() else "cpu"
    mtcnn = MTCNN(image_size=160, margin=20, device=device, post_process=True, keep_all=False, selection_method="largest")
    embedder = InceptionResnetV1(pretrained="vggface2").eval().to(device)
    clf = joblib.load("artifacts/svm.joblib")
    sc = joblib.load("artifacts/scaler.joblib")
    le = joblib.load("artifacts/encoder.joblib")
    cap = cv2.VideoCapture(0)
    while True:
        ok, frame = cap.read()
        if not ok: break
        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        pil = Image.fromarray(rgb)
        face = mtcnn(pil)
        if face is None:
            face = center_crop_resize(pil, 160)
        with torch.no_grad():
            emb = embedder(face.unsqueeze(0).to(device)).cpu().numpy()
        emb = sc.transform(emb)
        probs = clf.predict_proba(emb)[0]
        idx = np.argmax(probs)
        name = le.inverse_transform([idx])[0]
        conf = probs[idx]
        if conf < 0.6: name = "Unknown"
        cv2.putText(frame, f"{name} {conf:.2f}", (20, 60), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0,255,255), 3)
        cv2.imshow("Face Recognition", frame)
        if cv2.waitKey(1) & 0xFF == ord('q'): break
    cap.release(); cv2.destroyAllWindows()

if __name__ == "__main__":
    import sys
    if "ipykernel" in sys.modules:
        train()
    else:
        import argparse
        p = argparse.ArgumentParser()
        p.add_argument("--mode", choices=["train","webcam"], default="train")
        args = p.parse_args()
        if args.mode == "train": train()
        else: webcam()